# Base Kubernetes App
#
# Parent of: KafkaApp
# Child of: PipelineComponent
kubernetes-app:
  name: kubernetes-app
  namespace: namespace
  # `app` contains application-specific settings.
  # The fields below are just an example.
  app:
    image: exampleImage # Example
    debug: false # Example
    commandLine: {} # Example
  # Topic(s) from which the component will read input
  from:
    topics:
      ${pipeline_name}-input-topic:
        type: input
        # role: topic-role # only used if type is `extra` or `extra-pattern`
  # Topic(s) into which the component will write output
  to:
    topics:
      ${pipeline_name}-output-topic:
        type: output
        # role: topic-role # only used if type is `extra`
        keySchema: key-schema # must implement SchemaProvider to use
        valueSchema: value-schema
        partitions_count: 1
        replication_factor: 1
        configs: # https://kafka.apache.org/documentation/#topicconfigs
          cleanup.policy: compact
    models: # SchemaProvider is initiated with the values given here
      model: model
  # Pipeline prefix that will prefix every component name. If you wish to not
  # have any prefix you can specify an empty string.
  prefix: ${pipeline_name}-
  # Helm repository configuration
  repoConfig:
    repositoryName: my-repo
    url: https://bakdata.github.io/
    repoAuthFlags:
      username: user
      password: pass
      ca_file: /home/user/path/to/ca-file
      insecure_skip_tls_verify: false
  version: "1.0.0" # Helm chart version
#
# Base component for Kafka-based components.
#
# Parent of: ProducerApp, StreamsApp
# Child of: KubernetesApp
kafka-app:
  app:
    streams:
      brokers: ${brokers}
      schemaRegistryUrl: ${schema_registry_url}
    nameOverride: override-with-this-name
#
# StreamsApp component that configures a streams bootstrap app.
#
# Child of: KafkaApp
# More documentation on StreamsApp: https://github.com/bakdata/streams-bootstrap
streams-app:
  # No arbitrary keys are allowed under `app`.
  # Allowed configs:
  # https://github.com/bakdata/streams-bootstrap/tree/master/charts/streams-app
  app:
    # Streams Bootstrap streams section
    streams:
      inputTopics:
        - topic1
        - topic2
      outputTopic: output-topic
      inputPattern: input-pattern
      extraInputTopics:
        input_role1:
          - input_topic1
          - input_topic2
        input_role2:
          - input_topic3
          - input_topic4
      extraInputPatterns:
        pattern_role1: input_pattern1
      extraOutputTopics:
        output_role1: output_topic1
        output_role2: output_topic2
      errorTopic: error-topic
      config:
        my.streams.config: my.value
    autoscaling:
      consumerGroup: consumer-group
      lagThreshold: 0 # Average target value to trigger scaling actions.
      enabled: false # Whether to enable auto-scaling using KEDA.
      # This is the interval to check each trigger on.
      # https://keda.sh/docs/2.9/concepts/scaling-deployments/#pollinginterval
      pollingInterval: 30
      # The period to wait after the last trigger reported active before scaling
      # the resource back to 0. https://keda.sh/docs/2.9/concepts/scaling-deployments/#cooldownperiod
      cooldownPeriod: 300
      # The offset reset policy for the consumer if the the consumer group is
      # not yet subscribed to a partition.
      offsetResetPolicy: earliest
      # This setting is passed to the HPA definition that KEDA will create for a
      # given resource and holds the maximum number of replicas of the target resouce.
      # https://keda.sh/docs/2.9/concepts/scaling-deployments/#maxreplicacount
      maxReplicas: 1
      # Minimum number of replicas KEDA will scale the resource down to.
      # https://keda.sh/docs/2.7/concepts/scaling-deployments/#minreplicacount
      minReplicas: 0
      # If this property is set, KEDA will scale the resource down to this
      # number of replicas.
      # https://keda.sh/docs/2.9/concepts/scaling-deployments/#idlereplicacount
      idleReplicas: 0
      topics: # List of auto-generated Kafka Streams topics used by the streams app.
        - topic1
        - topic2
#
# Holds configuration to use as values for the streams bootstrap producer Helm
# chart.
#
# Child of: KafkaApp
# More documentation on ProducerApp: https://github.com/bakdata/streams-bootstrap
producer-app:
  # Allowed configs:
  # https://github.com/bakdata/streams-bootstrap/tree/master/charts/producer-app
  app:
    streams:
      outputTopic: output_topic
      extraOutputTopics:
        output_role1: output_topic1
        output_role2: output_topic2
#
# Kafka connector
#
# Parent of: KafkaSinkConnector, KafkaSourceConnector
# Child of: PipelineComponent
kafka-connector:
  name: kafka-connector
  namespace: namespace # Clean up jobs for the connector will run here
  # `app` contains application-specific settings. Extensive documentation on
  # connectors: https://kafka.apache.org/documentation/#connectconfigs
  app:
    tasks.max: 1 # example
  # Topic(s) from which the component will read input
  from:
    topics:
      ${pipeline_name}-input-topic:
        type: input
        # role: topic-role # only used if type is `extra`
  # Topic(s) into which the component will write output
  to:
    topics:
      ${pipeline_name}-output-topic:
        type: error
        keySchema: key-schema # must implement SchemaProvider to use
        valueSchema: value-schema
        partitions_count: 1
        replication_factor: 1
        configs: # https://kafka.apache.org/documentation/#topicconfigs
          cleanup.policy: compact
    models: # SchemaProvider is initiated with the values given here
      model: model
  # Pipeline prefix that will prefix every component name. If you wish to not
  # have any prefix you can specify an empty string.
  prefix: ${pipeline_name}-
  # Helm repository configuration for resetter
  repoConfig:
    repositoryName: my-repo
    url: https://bakdata.github.io/kafka-connect-resetter/
    repoAuthFlags:
      username: user
      password: pass
      ca_file: /home/user/path/to/ca-file
      insecure_skip_tls_verify: false
  version: "1.0.4" # Helm chart version
  # Overriding Kafka Connect Resetter Helm values. E.g. to override the
  # Image Tag etc.
  resetterValues:
    imageTag: "1.2.3"
#
# Kafka source connector
#
# Child of: KafkaConnector
kafka-source-connector:
  # offset.storage.topic
  # https://kafka.apache.org/documentation/#connect_running
  offsetTopic: offset_topic
#
# Kafka sink connector
#
# Child of: KafkaConnector
kafka-sink-connector:
  # No settings differ from `kafka-connector`

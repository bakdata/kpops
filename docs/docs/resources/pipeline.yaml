# `pipeline.yaml` contains the configurations for all components to be deployed
#
# In order to avoid repetition (for example with `namespace`), the user can set
# values in `defaults.yaml` for all apps of a certain type (could be specific
# like `producer` or broad like `kubernetes-app`). ]

# Base Kubernetes App
- type: kubernetes-app
  name: kubernetes-app # required
  namespace: namespace # required
  # `app` contains application-specific settings, hence it does not have a rigid
  # structure. The fields below are just an example.
  app: # required
    key1:
      key4: value3
    key2: value1
    key3: value2
  # Topic(s) from which the component will read input
  from:
    topics: # required
      ${pipeline_name}-input-topic:
        type: input # required
        role: topic-role
  # Topic(s) into which the component will write output
  to:
    topics: # required
      ${pipeline_name}-output-topic:
        type: output # required
        role: topic-role
        keySchema: key-schema
        valueSchema: value-schema
        partitions_count: 1
        replication_factor: 1
        configs: 
          config1: config1
    models: 
      model: model
  # Pipeline prefix that will prefix every component name. If you wish to not 
  # have any prefix you can specify an empty string.
  prefix: ${pipeline_name}-
  # Helm repository configuration
  repoConfig:
    repositoryName: my-repo # required
    url: https://bakdata.github.io/ # required
    repoAuthFlags: 
      username: user
      password: pass
      ca_file: /home/user/path/to/ca-file
      insecure_skip_tls_verify: false
  version: 1.0.0

# Base component for Kafka-based components.
# Producer or streaming apps should inherit from this class.
- type: kafka-app # required
  name: kafka-app # required
  namespace: namespace # required
  # `app` can contain application-specific settings, hence  the user is free to
  # add the key-value pairs they need. The fields that are specific to kafka
  # apps are marked with `# kafka-app-specific`
  app: # required
    streams: # required, kafka-app-specific
      brokers: ${broker} # required
      schemaRegistryUrl: ${schema_registry_url}
    nameOverride: override-with-this-name # kafka-app-specific
    key1:
      key4: value3
    key2: value1
    key3: value2
  # Topic(s) from which the component will read input
  from:
    topics: # required
      ${pipeline_name}-input-topic:
        type: input # required
        role: topic-role
  # Topic(s) into which the component will write output
  to:
    topics: # required
      ${pipeline_name}-output-topic:
        type: output # required
        role: topic-role
        keySchema: key-schema
        valueSchema: value-schema
        partitions_count: 1
        replication_factor: 1
        configs: 
          config1: config1
    models: 
      model: model
  # Pipeline prefix that will prefix every component name. If you wish to not 
  # have any prefix you can specify an empty string.
  prefix: ${pipeline_name}-
  # Helm repository configuration, the default value is given here
  repoConfig:
    repositoryName: bakdata-streams-bootstrap # required
    url: https://bakdata.github.io/streams-bootstrap/ # required
    repo_auth_flags:
      username: user
      password: pass
      ca_file: /home/user/path/to/ca-file
      insecure_skip_tls_verify: false
  version: "2.7.0"

# StreamsApp component that configures a streams bootstrap app.
# More documentation on StreamsApp: https://github.com/bakdata/streams-bootstrap
- type: streams-app # required
  name: streams-app # required
  namespace: namespace # required
  # `app` can contain application-specific settings, hence  the user is free to
  # add the key-value pairs they need. The fields that are specific to streams
  # apps are marked with `# streams-app-specific`
  app: # required
    # Streams Bootstrap streams section
    streams: # required, streams-app-specific
      brokers: ${broker} # required
      schemaRegistryUrl: ${schema_registry_url}
      inputTopics:
        - "topic1"
        - "topic2"
      outputTopic: output-topic
      inputPattern: input-pattern
      extraInputTopics:
        input_role1:
          - input_topic1
          - input_topic2
        input_role2:
          - input_topic3
          - input_topic4
      extraInputPatterns:
        pattern_role1: input_pattern1
      extraOutputTopics: 
        output_role1: output_topic1
        output_role2: output_topic2
      errorTopic: error-topic
      config: 
        my.streams.config: my.value
    nameOverride: override-with-this-name # streams-app-specific
    autoscaling: # streams-app-specific
      consumergroup: consumer-group # required
      topics:
        - "topic1"
        - "topic2"
    key1:
      key4: value3
    key2: value1
    key3: value2
  # Topic(s) from which the component will read input
  from:
    topics: # required
      ${pipeline_name}-input-topic:
        type: input # required
        role: topic-role
  # Topic(s) into which the component will write output
  to:
    topics: # required
      ${pipeline_name}-output-topic:
        type: output # required
        role: topic-role
        keySchema: key-schema
        valueSchema: value-schema
        partitions_count: 1
        replication_factor: 1
        configs: 
          config1: config1
    models: 
      model: model
  # Pipeline prefix that will prefix every component name. If you wish to not 
  # have any prefix you can specify an empty string.
  prefix: ${pipeline_name}-
  # Helm repository configuration, the default value is given here
  repoConfig:
    repositoryName: bakdata-streams-bootstrap # required
    url: https://bakdata.github.io/streams-bootstrap/ # required
    repo_auth_flags:
      username: user
      password: pass
      ca_file: /home/user/path/to/ca-file
      insecure_skip_tls_verify: false
  version: "2.7.0"

# Holds configuration to use as values for the streams bootstrap produce helm
# chart.
# More documentation on ProducersApp:
# https://github.com/bakdata/streams-bootstrap
- type: producer # required
  name: producer # required
  namespace: namespace # required
  # `app` can contain application-specific settings, hence  the user is free to
  # add the key-value pairs they need. The fields that are specific to producers
  # are marked with `# producer-specific`
  app: # required
    streams: # required, producer-specific
      brokers: ${broker} # required
      schemaRegistryUrl: ${schema_registry_url}
      outputTopic: output_topic
      extraOutputTopics: 
        output_role1: output_topic1
        output_role2: output_topic2
    nameOverride: override-with-this-name # kafka-app-specific
    kkey1:
      key4: value3
    key2: value1
    key3: value2
  # Topic(s) from which the component will read input
  from:
    topics: # required
      ${pipeline_name}-input-topic:
        type: input # required
        role: topic-role
  # Topic(s) into which the component will write output
  to:
    topics: # required
      ${pipeline_name}-output-topic:
        type: output # required
        role: topic-role
        keySchema: key-schema
        valueSchema: value-schema
        partitions_count: 1
        replication_factor: 1
        configs: 
          config1: config1
    models: 
      model: model
  # Pipeline prefix that will prefix every component name. If you wish to not 
  # have any prefix you can specify an empty string.
  prefix: ${pipeline_name}-
  # Helm repository configuration, the default value is given here
  repoConfig:
    repositoryName: bakdata-streams-bootstrap # required
    url: https://bakdata.github.io/streams-bootstrap/ # required
    repo_auth_flags:
      username: user
      password: pass
      ca_file: /home/user/path/to/ca-file
      insecure_skip_tls_verify: false
  version: "2.7.0"

# Kafka source connector
- type: kafka-source-connector
  name: kafka-source-connector # required
  namespace: namespace # required
  # `app` contains application-specific settings, hence it does not have a rigid
  # structure. The fields below are just an example.
  app: # required
    key1:
      key4: value3
    key2: value1
    key3: value2
  # Topic(s) from which the component will read input
  from:
    topics: # required
      ${pipeline_name}-input-topic:
        type: input # required
        role: topic-role
  # Topic(s) into which the component will write output
  to:
    topics: # required
      ${pipeline_name}-output-topic:
        type: output # required
        role: topic-role
        keySchema: key-schema
        valueSchema: value-schema
        partitions_count: 1
        replication_factor: 1
        configs: 
          config1: config1
    models: 
      model: model
  # Pipeline prefix that will prefix every component name. If you wish to not 
  # have any prefix you can specify an empty string.
  prefix: ${pipeline_name}-
  # Helm repository configuration
  repoConfig:
    repositoryName: my-repo # required
    url: https://bakdata.github.io/kafka-connect-resetter/ # required
    repoAuthFlags: 
      username: user
      password: pass
      ca_file: /home/user/path/to/ca-file
      insecure_skip_tls_verify: false
  version: "1.0.4"
  # Overriding Kafka Connect Resetter Helm values. E.g. to override the
  # Image Tag etc.
  resetterValues:
    imageTag: 1.2.3
  offsetTopic: offset_topic
    
- type: kafka-sink-connector
  name: kafka-sink-connector # required
  namespace: namespace # required
  # `app` contains application-specific settings, hence it does not have a rigid
  # structure. The fields below are just an example.
  app: # required
    key1:
      key4: value3
    key2: value1
    key3: value2
  # Topic(s) from which the component will read input
  from:
    topics: # required
      ${pipeline_name}-input-topic:
        type: input # required
        role: topic-role
  # Topic(s) into which the component will write output
  to:
    topics: # required
      ${pipeline_name}-output-topic:
        type: output # required
        role: topic-role
        keySchema: key-schema
        valueSchema: value-schema
        partitions_count: 1
        replication_factor: 1
        configs: 
          config1: config1
    models: 
      model: model
  # Pipeline prefix that will prefix every component name. If you wish to not 
  # have any prefix you can specify an empty string.
  prefix: ${pipeline_name}-
  # Helm repository configuration
  repoConfig:
    repositoryName: my-repo # required
    url: https://bakdata.github.io/kafka-connect-resetter/ # required
    repoAuthFlags: 
      username: user
      password: pass
      ca_file: /home/user/path/to/ca-file
      insecure_skip_tls_verify: false
  version: "1.0.4"
  # Overriding Kafka Connect Resetter Helm values. E.g. to override the
  # Image Tag etc.
  resetterValues:
    imageTag: 1.2.3
  offsetTopic: offset_topic

- _cleaner:
    app:
      commandLine:
        FAKE_ARG: override-arg
      image: example-registry/fake-image
      imageTag: 0.0.1
      schedule: 20 3/8 * * *
      streams:
        brokers: http://k8kafka-cp-kafka-headless.kpops.svc.cluster.local:9092
        outputTopic: resources-pipeline-with-envs-input-producer
        schemaRegistryUrl: http://localhost:8081/
    name: input-producer
    namespace: example-namespace
    prefix: resources-pipeline-with-envs-
    repo_config:
      repo_auth_flags:
        insecure_skip_tls_verify: false
      repository_name: bakdata-streams-bootstrap
      url: https://bakdata.github.io/streams-bootstrap/
    suffix: -clean
    type: producer-app-cleaner
    version: 2.4.2
  app:
    commandLine:
      FAKE_ARG: override-arg
    image: example-registry/fake-image
    imageTag: 0.0.1
    schedule: 20 3/8 * * *
    streams:
      brokers: http://k8kafka-cp-kafka-headless.kpops.svc.cluster.local:9092
      outputTopic: resources-pipeline-with-envs-input-producer
      schemaRegistryUrl: http://localhost:8081/
  name: input-producer
  namespace: example-namespace
  prefix: resources-pipeline-with-envs-
  repo_config:
    repo_auth_flags:
      insecure_skip_tls_verify: false
    repository_name: bakdata-streams-bootstrap
    url: https://bakdata.github.io/streams-bootstrap/
  to:
    models:
      com/bakdata/kafka/fake: 1.0.0
    topics:
      resources-pipeline-with-envs-input-producer:
        configs:
          cleanup.policy: compact,delete
        partitions_count: 12
        type: output
        value_schema: com.bakdata.fake.Produced
  type: scheduled-producer
  version: 2.4.2
- _cleaner:
    app:
      autoscaling:
        consumerGroup: converter-resources-pipeline-with-envs-converter
        cooldownPeriod: 300
        enabled: true
        lagThreshold: 10000
        maxReplicas: 1
        minReplicas: 0
        offsetResetPolicy: earliest
        pollingInterval: 30
        topics: []
      commandLine:
        CONVERT_XML: true
      persistence:
        enabled: false
      resources:
        limits:
          memory: 2G
        requests:
          memory: 2G
      statefulSet: false
      streams:
        brokers: http://k8kafka-cp-kafka-headless.kpops.svc.cluster.local:9092
        config:
          large.message.id.generator: com.bakdata.kafka.MurmurHashIdGenerator
        errorTopic: resources-pipeline-with-envs-converter-error
        inputTopics:
        - resources-pipeline-with-envs-input-producer
        outputTopic: resources-pipeline-with-envs-converter
        schemaRegistryUrl: http://localhost:8081/
    name: converter
    namespace: example-namespace
    prefix: resources-pipeline-with-envs-
    repo_config:
      repo_auth_flags:
        insecure_skip_tls_verify: false
      repository_name: bakdata-streams-bootstrap
      url: https://bakdata.github.io/streams-bootstrap/
    suffix: -clean
    type: streams-app-cleaner
    version: 2.4.2
  app:
    autoscaling:
      consumerGroup: converter-resources-pipeline-with-envs-converter
      cooldownPeriod: 300
      enabled: true
      lagThreshold: 10000
      maxReplicas: 1
      minReplicas: 0
      offsetResetPolicy: earliest
      pollingInterval: 30
      topics: []
    commandLine:
      CONVERT_XML: true
    persistence:
      enabled: false
    resources:
      limits:
        memory: 2G
      requests:
        memory: 2G
    statefulSet: false
    streams:
      brokers: http://k8kafka-cp-kafka-headless.kpops.svc.cluster.local:9092
      config:
        large.message.id.generator: com.bakdata.kafka.MurmurHashIdGenerator
      errorTopic: resources-pipeline-with-envs-converter-error
      inputTopics:
      - resources-pipeline-with-envs-input-producer
      outputTopic: resources-pipeline-with-envs-converter
      schemaRegistryUrl: http://localhost:8081/
  name: converter
  namespace: example-namespace
  prefix: resources-pipeline-with-envs-
  repo_config:
    repo_auth_flags:
      insecure_skip_tls_verify: false
    repository_name: bakdata-streams-bootstrap
    url: https://bakdata.github.io/streams-bootstrap/
  to:
    models: {}
    topics:
      resources-pipeline-with-envs-converter:
        configs:
          cleanup.policy: compact,delete
          retention.ms: '-1'
        partitions_count: 50
        type: output
      resources-pipeline-with-envs-converter-error:
        configs:
          cleanup.policy: compact,delete
        partitions_count: 10
        type: error
        value_schema: com.bakdata.kafka.DeadLetter
  type: converter
  version: 2.4.2
- _cleaner:
    app:
      autoscaling:
        consumerGroup: filter-resources-pipeline-with-envs-filter
        cooldownPeriod: 300
        enabled: true
        lagThreshold: 10000
        maxReplicas: 4
        minReplicas: 4
        offsetResetPolicy: earliest
        pollingInterval: 30
        topics:
        - resources-pipeline-with-envs-filter
      commandLine:
        TYPE: nothing
      image: fake-registry/filter
      imageTag: 2.4.1
      persistence:
        enabled: false
      replicaCount: 4
      resources:
        requests:
          memory: 3G
      statefulSet: false
      streams:
        brokers: http://k8kafka-cp-kafka-headless.kpops.svc.cluster.local:9092
        config:
          large.message.id.generator: com.bakdata.kafka.MurmurHashIdGenerator
        errorTopic: resources-pipeline-with-envs-filter-error
        inputTopics:
        - resources-pipeline-with-envs-converter
        outputTopic: resources-pipeline-with-envs-filter
        schemaRegistryUrl: http://localhost:8081/
    name: filter
    namespace: example-namespace
    prefix: resources-pipeline-with-envs-
    repo_config:
      repo_auth_flags:
        insecure_skip_tls_verify: false
      repository_name: bakdata-streams-bootstrap
      url: https://bakdata.github.io/streams-bootstrap/
    suffix: -clean
    type: streams-app-cleaner
    version: 2.4.2
  app:
    autoscaling:
      consumerGroup: filter-resources-pipeline-with-envs-filter
      cooldownPeriod: 300
      enabled: true
      lagThreshold: 10000
      maxReplicas: 4
      minReplicas: 4
      offsetResetPolicy: earliest
      pollingInterval: 30
      topics:
      - resources-pipeline-with-envs-filter
    commandLine:
      TYPE: nothing
    image: fake-registry/filter
    imageTag: 2.4.1
    persistence:
      enabled: false
    replicaCount: 4
    resources:
      requests:
        memory: 3G
    statefulSet: false
    streams:
      brokers: http://k8kafka-cp-kafka-headless.kpops.svc.cluster.local:9092
      config:
        large.message.id.generator: com.bakdata.kafka.MurmurHashIdGenerator
      errorTopic: resources-pipeline-with-envs-filter-error
      inputTopics:
      - resources-pipeline-with-envs-converter
      outputTopic: resources-pipeline-with-envs-filter
      schemaRegistryUrl: http://localhost:8081/
  name: filter
  namespace: example-namespace
  prefix: resources-pipeline-with-envs-
  repo_config:
    repo_auth_flags:
      insecure_skip_tls_verify: false
    repository_name: bakdata-streams-bootstrap
    url: https://bakdata.github.io/streams-bootstrap/
  to:
    models: {}
    topics:
      resources-pipeline-with-envs-filter:
        configs:
          retention.ms: '-1'
        partitions_count: 50
        type: output
      resources-pipeline-with-envs-filter-error:
        configs:
          cleanup.policy: compact,delete
        partitions_count: 1
        type: error
        value_schema: com.bakdata.kafka.DeadLetter
  type: filter
  version: 2.4.2

